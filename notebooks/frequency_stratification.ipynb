{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/users/jolivier/oak/users/jolivier/repos/hla-assoc/\"\n",
    "outpath = \"output/frequency_stratification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv of all posterior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map phenotype names to id codes\n",
    "phe_names = {}\n",
    "HC_map = open(path + \"data/highconfidenceqc_map.csv\",\"r\")\n",
    "HC_map.readline()\n",
    "for line in HC_map.readlines():\n",
    "    line = line.split(\",\")\n",
    "    phe_names[line[0]] = line[1][:-1]\n",
    "HC_map.close()\n",
    "cancer_map = open(path + \"data/cancermap.csv\",\"r\")\n",
    "cancer_map.readline()\n",
    "for line in cancer_map.readlines():\n",
    "    line =line.split(\",\")\n",
    "    phe_names[line[0]] = line[1][:-1]\n",
    "cancer_map.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of values we're interested in and write to csv\n",
    "all_post = {\"phe_ID\" : [], \"phenotype\" : [], \"allelotype\" : [], \"posterior_probability\" : []}\n",
    "df_post = pd.read_csv(path + \"scripts/output/hap_post_plot/phe_hap_table_post_adjp.csv\", index_col = 0, header=0)\n",
    "for phe in df_post.index.values:\n",
    "    for alel in df_post.columns.values:\n",
    "        post = df_post[alel][phe]\n",
    "        if not pd.isnull(post):\n",
    "            all_post[\"phe_ID\"].append(phe)\n",
    "            all_post[\"phenotype\"].append(phe_names[phe])\n",
    "            all_post[\"allelotype\"].append(alel)\n",
    "            all_post[\"posterior_probability\"].append(post)\n",
    "all_post_df = pd.DataFrame(all_post).sort_values(by=[\"posterior_probability\"], ascending=False)\n",
    "all_post_df.to_csv(outpath + \"all_post_BMA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of significant BMA findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of post probabilities above 0.8 : 60\n",
      "Number of phenotypes with post probabilities above 0.8: 31\n",
      "Number of allelotypes with post probabilities above 0.8: 30\n"
     ]
    }
   ],
   "source": [
    "cutoff = 0.8\n",
    "cut_all_post_df = all_post_df[all_post_df[\"posterior_probability\"] > cutoff]\n",
    "print(\"Number of post probabilities above {} : {}\".format(cutoff,len(cut_all_post_df)))\n",
    "print(\"Number of phenotypes with post probabilities above {}: {}\".format(cutoff,len(set(cut_all_post_df[\"phe_ID\"]))))\n",
    "print(\"Number of allelotypes with post probabilities above {}: {}\".format(cutoff,len(set(cut_all_post_df[\"allelotype\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find frequency breakdown of allelotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create allele frequency dictionary\n",
    "allele_freq_file = open(path + \"notebooks/output/check_firth/allele_freq.csv\",\"r\")\n",
    "allele_freq_file.readline()\n",
    "allele_freq_dict = {}\n",
    "for line in allele_freq_file.readlines():\n",
    "    line = line.split(\",\")\n",
    "    allele_freq_dict[line[0]] = int(line[1][:-3])\n",
    "allele_freq_file.close()\n",
    "\n",
    "BMA_alleles_file = open(path + \"notebooks/output/compare_cutoff_pvals/BMA_allele_torun.txt\", \"r\")\n",
    "BMA_alleles = set(BMA_alleles_file.readline().split())\n",
    "BMA_alleles_file.close()\n",
    "\n",
    "# only consider alleles that we ran BMA on\n",
    "for key in allele_freq_dict.keys():\n",
    "    if key not in BMA_alleles:\n",
    "        del allele_freq_dict[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency cutoffs being used and number of allelotypes in each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num less than  0.01: 4 \n",
      "num [0.01,0.05): 10 \n",
      "num greater than 0.05: 48\n"
     ]
    }
   ],
   "source": [
    "num_individuals = 337208.\n",
    "thresh1 = 0.01\n",
    "thresh2 = 0.05\n",
    "\n",
    "bins = [[],[],[]]\n",
    "\n",
    "for key in allele_freq_dict.keys():\n",
    "    perc = allele_freq_dict[key]/num_individuals\n",
    "    if perc < thresh1:\n",
    "        bins[0].append(key)\n",
    "    elif perc < thresh2:\n",
    "        bins[1].append(key)\n",
    "    else:\n",
    "        bins[2].append(key)\n",
    "print(\"num less than  {}: {} \\nnum [{},{}): {} \\nnum greater than {}: {}\".format(thresh1,len(bins[0]), thresh1, thresh2,len(bins[1]), thresh2,len(bins[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_post = pd.read_csv(path + \"scripts/output/hap_post_plot/phe_hap_table_post_adjp.csv\", header=0, index_col=0)\n",
    "full_EV = pd.read_csv(path + \"scripts/output/hap_post_plot/phe_hap_table_EV_adjp.csv\", header=0, index_col=0)\n",
    "full_SD = pd.read_csv(path + \"scripts/output/hap_post_plot/phe_hap_table_SD_adjp.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into rare, midlevel, and common alleles\n",
    "rare_post = full_post[bins[0]]\n",
    "rare_post.to_csv(outpath + \"rare_post_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "rare_EV = full_EV[bins[0]]\n",
    "rare_EV.to_csv(outpath + \"rare_EV_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "rare_SD = full_SD[bins[0]]\n",
    "rare_SD.to_csv(outpath + \"rare_SD_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "\n",
    "\n",
    "mid_post = full_post[bins[1]]\n",
    "mid_post.to_csv(outpath + \"uncommon_post_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "mid_EV = full_EV[bins[1]]\n",
    "mid_EV.to_csv(outpath + \"uncommon_EV_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "mid_SD = full_SD[bins[1]]\n",
    "mid_SD.to_csv(outpath + \"uncommon_SD_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "\n",
    "\n",
    "common_post = full_post[bins[2]]\n",
    "common_post.to_csv(outpath + \"common_post_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "common_EV = full_EV[bins[2]]\n",
    "common_EV.to_csv(outpath + \"common_EV_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")\n",
    "common_SD = full_SD[bins[2]]\n",
    "common_SD.to_csv(outpath + \"common_SD_\" + str(thresh1) + \"_\" + str(thresh2) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
