{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Plink Results\n",
    "\n",
    "Read plink results and keep only the test results for the HLA alleles.\n",
    "\n",
    "Julia made a notebook that sort of does this too, but I'm going to leave this one\n",
    "because it makes a single file that is nice to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cdpybio as cpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outdir = os.path.realpath(os.path.join('../output/process_plink_results'))\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traits = pd.read_table('../data/traits.tsv', header=0, index_col=0)\n",
    "# Rename cancer codes to match codes that were used in HLA analysis.\n",
    "traits.index = [x.replace('cancer', '') for x in traits.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fns = glob.glob('/oak/stanford/groups/mrivas/users/jolivier/repos/hla-assoc/data/PLINK_results/*hybrid')\n",
    "codes = [os.path.split(x)[1].split('.')[0] for x in fns]\n",
    "\n",
    "out_fn = os.path.join(outdir, 'plink_results_all.tsv.gz')\n",
    "if not os.path.exists(out_fn):\n",
    "    dfs = []\n",
    "    for fn in fns:\n",
    "        t = cpb.plink.read_logistic2(fn)\n",
    "        t['code'] = os.path.split(fn)[1].split('.')[0]\n",
    "        t = t[['code', 'FIRTH?', 'TEST', 'OBS_CT', 'OR', 'SE', 'T_STAT', 'P']]\n",
    "        dfs.append(t)\n",
    "    results = pd.concat(dfs)\n",
    "    results.to_csv(out_fn, sep='\\t', compression='gzip')\n",
    "else:\n",
    "    results = pd.read_table(out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results by allele and disease frequency\n",
    "hla = pd.read_table('/oak/stanford/groups/mrivas/ukbb/24983/hla/ukb_hla_v2.txt')\n",
    "covar = pd.read_table('/oak/stanford/groups/mrivas/ukbb/24983/phe_qc/ukb24983_GWAS_covar.phe', \n",
    "                      index_col=0)\n",
    "hla.index = covar.index\n",
    "remove = pd.read_table('/oak/stanford/groups/mrivas/ukbb/24983/phe_qc/ukb24983_remove.phe',\n",
    "                       index_col=0, header=None, squeeze=True)\n",
    "hla = hla.drop(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        regtype category  numcases                         phenotype\n",
      "HC69   logistic       HC     482.0                polycythaemia_vera\n",
      "HC432  logistic       HC     487.0             mitral_valve_prolapse\n",
      "HC421  logistic       HC     478.0           other_abdominal_problem\n",
      "HC352  logistic       HC     474.0  systemic_lupus_erythematosis/sle\n",
      "HC12   logistic       HC     492.0  testicular_problems_(not_cancer)\n"
     ]
    }
   ],
   "source": [
    "# Note: this relies on this additive_assoc_adj_p_all.csv file because I'm not\n",
    "# exactly sure where the original list of phenotypes came from. It doesn't\n",
    "# really matter, I just want to make sure I know which phenotypes were included.\n",
    "additive_res = pd.read_csv('../manuscript/additive_assoc_adj_p_all.csv', index_col=0)\n",
    "\n",
    "shared = list(set(codes) & set(traits.index))\n",
    "missing = list(set(additive_res.index) - set(traits[traits['numcases'] >= 500].index))\n",
    "print(traits.loc[missing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the number of cases for some of the diseases is less than 500\n",
    "according to the counts I have from the gcorr app. Julia made a mistake \n",
    "when calculating the disease frequencies in the `check_firth` notebook. These diseases\n",
    "are ones that were included but shouldn't have been if we took 500 as a cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        regtype category  numcases           phenotype\n",
      "HC278  logistic       HC     477.0   cerebral_aneurysm\n",
      "HC375  logistic       HC     477.0  alcohol_dependency\n",
      "HC256  logistic       HC     476.0        fracture_toe\n"
     ]
    }
   ],
   "source": [
    "print(traits.loc[list(set(traits[traits.numcases >= 470].index) & set(codes) - \n",
    "                      set(additive_res.index))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are three phenotypes we could've included if we used a cutoff of 470. I think\n",
    "it's fine to leave these out since the cutoff was arbitrary anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phenos = list(additive_res.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = os.path.join(\"../private_output/print_rds/ukb_hla_v2_rounded_remove.txt\")\n",
    "dosages = pd.read_csv(fn, index_col=0)\n",
    "allele_freqs = dosages.sum() / float(dosages.shape[0])\n",
    "alleles = list(allele_freqs[allele_freqs >= 0.001].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(outdir, 'phenos.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(phenos) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(outdir, 'alleles.txt'), 'w') as f:\n",
    "    f.write('\\n'.join(alleles) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(results['ID']) & set(alleles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(results['code']) & set(phenos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_pvals = pd.read_csv('../output/compare_cutoff_pvals/adj_p_vals.csv', index_col=0)\n",
    "adj_pvals = adj_pvals.stack().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_f = results[results['code'].isin(phenos)]\n",
    "results_f = results_f[results_f['ID'].isin(alleles)]\n",
    "results_f = results_f[results_f['TEST'] == 'ADD']\n",
    "results_f = results_f.set_index(['code', 'ID']).sort_index()\n",
    "results_f['adj_pval'] = adj_pvals\n",
    "out_fn = os.path.join(outdir, 'plink_results_filtered.tsv.gz')\n",
    "results_f.to_csv(out_fn, sep='\\t', compression='gzip')\n",
    "\n",
    "out_fn = os.path.join(outdir, 'plink_results_filtered_sig.tsv.gz')\n",
    "results_sig = results_f[results_f.adj_pval < 0.05]\n",
    "results_sig.to_csv(out_fn, sep='\\t', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
